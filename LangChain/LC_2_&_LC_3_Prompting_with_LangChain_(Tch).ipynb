{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **LangChain**\n",
        "\n",
        "In the series of lectures, we have learnt how to use the OpenAI API to communicate with the OpenAI servers.\n",
        "\n",
        "Now, we learn how to harness the full potential of these LLM using LangChain which is a Python framework connecting these models to the outside \"world\" including external data sources (PDF, Websites) and giving it web browsing capabilties"
      ],
      "metadata": {
        "id": "EpfeKAeFRG0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LC-2: What is LangChain**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "LangChain offers a modular architecture that enables developers to easily combine different components, such as pre-trained language models and data storage systems, to build chatbots, automated writing assistants, and other natural language processing applications\n",
        "\n",
        "LangChain is built around several essential components, including models, prompts, memory, indexes, chains, and agents. Models in LangChain generate text, images, and other outputs in response to a given prompt, while agents utilize LLMs to determine the appropriate steps to take, such as conducting web searches or utilizing calculators."
      ],
      "metadata": {
        "id": "_TOIpOKgbsJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LC-3: Prompting in LangChain"
      ],
      "metadata": {
        "id": "Yit9cTHiCeim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Setting Up**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "RnAt4-pgdyBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "from langchain > 0.17, be sure to install langchain_openai\n",
        "```"
      ],
      "metadata": {
        "id": "TcDukJudd5J0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4QrTc3vQ8Bc"
      },
      "outputs": [],
      "source": [
        "# Installing all the dependencies\n",
        "!pip install -q openai langchain langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "97xPm7oCziVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Communicating with OpenAI Models**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "UxvbxhsqeQy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reference: https://python.langchain.com/docs/integrations/chat/openai**"
      ],
      "metadata": {
        "id": "l-mv6SRZmRS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "X1kUMFwtUTQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(temperature = 0, openai_api_key = userdata.get(\"OPENAI_API_KEY\"))"
      ],
      "metadata": {
        "id": "aArq2fKjUdU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.invoke(\n",
        "    [\n",
        "        SystemMessage(content=\"You are a professional poet creator\"),\n",
        "        HumanMessage(content=\"Create a poem depicting the business of the early Wet Market in Singapore. Use Singlish in the poem\")\n",
        "    ]\n",
        ")\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "OIB9bkhgYWnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.invoke(\n",
        "    [\n",
        "        SystemMessage(content=\"You are a tour guide who is going to recommend a dish to try in Singapore\"),\n",
        "        HumanMessage(content=\"What one dish should I try in Singapore today?\"),\n",
        "        AIMessage(content=\"Kaya Toast\"),\n",
        "        HumanMessage(content=\"How do I go about preparing that dish?\")\n",
        "        AIMessage('Use butter and toast the bread'),\n",
        "        HumanMessage('Give something which also complements kaya toast')\n",
        "    ]\n",
        ")\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "EueJ5IN6ZtMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prompts in LangChain**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "OaEumTCTlaMO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have learnt how to use the OpenAI Models in the LangChain way, let's learn how to utilise the prompting features in LangChain"
      ],
      "metadata": {
        "id": "0UAlR66SxqqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI"
      ],
      "metadata": {
        "id": "4amkGQ2Ulo5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(openai_api_key = userdata.get(\"OPENAI_API_KEY\"))"
      ],
      "metadata": {
        "id": "jDi3Hf9rlmoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_prompt = \"what do you think of pineapples on pizza?\"\n",
        "print(llm.invoke(sample_prompt))"
      ],
      "metadata": {
        "id": "NnNCTa7ylfAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt Templates**"
      ],
      "metadata": {
        "id": "eNQH8LgenAP7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt Templates in LangChain serve to create dynamic prompts for language models.\n",
        "\n",
        "It consist of:\n",
        "\n",
        "`template`: Backbone template used for different prompting scenarios\n",
        "\n",
        "`input_variables`: words to change in the template"
      ],
      "metadata": {
        "id": "DL-IJtWgy-_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "30JrRTZdnDPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"You are a professional giving advise in the {field}\"\n",
        "prompt = PromptTemplate(template = template, input_variables=[\"field\"])"
      ],
      "metadata": {
        "id": "CVkJ0tknvyrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"You are a poet creator creating poem in this {place}\"\n",
        "prompt = PromptTemplate(template = template, input_variables = [\"place\"])"
      ],
      "metadata": {
        "id": "BoebTcG4hed2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chains in LangChain**\n",
        "\n",
        "Chaining is a key concept used to define sequences of calls, which can include calls to a LLM's, tool (e.g. access the  web) , or a data preprocessing step (e.g. connect to our own documents).\n",
        "\n",
        "Chains in LangChain allow you to include these different features to create applications specific to your own use case.\n",
        "\n",
        "Understanding Chains\n",
        "\n",
        "* `LLMChain`: LLM chain takes a prompt template, formats it with user input, and returns the response from a large language model (LLM)."
      ],
      "metadata": {
        "id": "dD5AdgRW3vu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "VznaIRWsvtgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(openai_api_key = userdata.get(\"OPENAI_API_KEY\"))"
      ],
      "metadata": {
        "id": "9XHzzj_NwCN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(prompt = prompt, llm = llm)"
      ],
      "metadata": {
        "id": "hHKVoM2qwEPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# field = \"Artifical Intelligence\"\n",
        "# print(llm_chain.invoke(field)[\"text\"])\n",
        "print(llm_chain.invoke(\"Artifical Intelligence\")['text'])"
      ],
      "metadata": {
        "id": "dsWt29rawJaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm_chain.invoke(\"Chinatown\")['text'])"
      ],
      "metadata": {
        "id": "VnT0EAGBhobF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}